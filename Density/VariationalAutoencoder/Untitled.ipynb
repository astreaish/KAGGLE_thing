{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "/Users/mara/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from VAE import VAE\n",
    "import cPickle\n",
    "import gzip\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from sklearn import preprocessing as prep\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cross_validation as crval\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.svm import LinearSVC\n",
    "import pylab\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import csv\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def write_answers(predictions, description):\n",
    "    fp=open(description+'.txt','w')\n",
    "    fp.write('Point_ID,Output\\n')\n",
    "    i=1\n",
    "    for a in predictions:\n",
    "        fp.write(str(i)+','+str(a)+'\\n')\n",
    "        i+=1\n",
    "    fp.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: \n",
      "(5000, 14)\n",
      "Original mean: 0.189320842874 and std:2.26790054052\n",
      "After-cleaning mean: 4.3038588566e-17 and std: 1.0\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "with open('density_data.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row1 in reader:\n",
    "        X.append(row1)\n",
    "#print size(X)\n",
    "\n",
    "X=np.asarray(X)\n",
    "X=X[:,1:15] # removing the first column since it contains indexes\n",
    "\n",
    "print 'Data dimensions: ' \n",
    "print X.shape\n",
    "\n",
    "X=X.astype(np.float)\n",
    "\n",
    "\n",
    "X= np.ravel(X)\n",
    "X= X.reshape(5000, 14)\n",
    "#print(shape(X))\n",
    "\n",
    "# splitting .. \n",
    "selX = X # (atm) we take all data --> no splitting \n",
    "\n",
    "# scaling\n",
    "std_scal=prep.StandardScaler()\n",
    "selX_scaled=std_scal.fit_transform(selX)\n",
    "print('Original mean: ' +str(mean(selX))+' and std:'+ str(std(selX)))\n",
    "print('After-cleaning mean: '+str(mean(selX_scaled))+' and std: '+str(std(selX_scaled)))\n",
    "\n",
    "\n",
    "X=selX_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "hu_encoder = 400\n",
    "hu_decoder = 400\n",
    "n_latent = 7\n",
    "continuous = True\n",
    "n_epochs = 10\n",
    "\n",
    "if continuous:\n",
    "    print \"Loading dataset\"\n",
    "    # Retrieved from: http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "    #f = open('freyfaces.pkl', 'rb')\n",
    "    #x = cPickle.load(f)\n",
    "    #f.close()\n",
    "    x_train = X\n",
    "    x_valid = X[0:100,:]\n",
    "else:\n",
    "    print \"Loading MNIST data\"\n",
    "    # Retrieved from: http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    (x_train, t_train), (x_valid, t_valid), (x_test, t_test) = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "path = \"./\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 14)\n",
      "(5000, 14)\n"
     ]
    }
   ],
   "source": [
    "print x_valid.shape\n",
    "print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiating model\n",
      "iterating\n",
      "Epoch 1 finished. LB: -19.5723436237, time: 73.3275411129\n",
      "Epoch 2 finished. LB: -17.0188632784, time: 73.4030570984\n",
      "Epoch 3 finished. LB: -14.4730641975, time: 118.850583076\n",
      "Epoch 4 finished. LB: -12.1290712175, time: 86.8832769394\n",
      "Epoch 5 finished. LB: -10.3152590685, time: 88.7744169235\n",
      "Epoch 6 finished. LB: -8.36191460827, time: 84.8691821098\n",
      "Epoch 7 finished. LB: -7.07385940079, time: 86.9280591011\n",
      "Epoch 8 finished. LB: -6.15108646007, time: 82.2275259495\n",
      "Epoch 9 finished. LB: -5.42439088199, time: 90.7636489868\n",
      "Epoch 10 finished. LB: -4.86506698872, time: 96.4873869419\n",
      "LB on validation set: -4.31701334309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"instantiating model\"\n",
    "model = VAE(continuous, hu_encoder, hu_decoder, n_latent, x_train)\n",
    "\n",
    "\n",
    "batch_order = np.arange(int(model.N / model.batch_size))\n",
    "epoch = 0\n",
    "LB_list = []\n",
    "\n",
    "if os.path.isfile(path + \"params.pkl\"):\n",
    "    print \"Restarting from earlier saved parameters!\"\n",
    "    model.load_parameters(path)\n",
    "    LB_list = np.load(path + \"LB_list.npy\")\n",
    "    epoch = len(LB_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print \"iterating\"\n",
    "    while epoch < n_epochs:\n",
    "        epoch += 1\n",
    "        start = time.time()\n",
    "        np.random.shuffle(batch_order)\n",
    "        LB = 0.\n",
    "\n",
    "        for batch in batch_order:\n",
    "            batch_LB = model.update(batch, epoch)\n",
    "            LB += batch_LB\n",
    "\n",
    "        LB /= len(batch_order)\n",
    "\n",
    "        LB_list = np.append(LB_list, LB)\n",
    "        print \"Epoch {0} finished. LB: {1}, time: {2}\".format(epoch, LB, time.time() - start)\n",
    "        np.save(path + \"LB_list.npy\", LB_list)\n",
    "        model.save_parameters(path)\n",
    "\n",
    "    valid_LB = model.likelihood(x_valid)\n",
    "    print \"LB on validation set: {0}\".format(valid_LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "print x_train[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=np.zeros(3)\n",
    "for i in range(3):\n",
    "    l[i]=model.likelihood(x_train[i,:].reshape(1,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.05985663 -2.5445971  -3.54184532]\n"
     ]
    }
   ],
   "source": [
    "print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=np.zeros(5000)\n",
    "for i in range(5000):\n",
    "    l[i]=model.likelihood(x_train[i,:].reshape(1,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.35839879 -5.44899808 -0.27007366 ..., -6.64637241 -4.89164263\n",
      " -4.29061996]\n"
     ]
    }
   ],
   "source": [
    "print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answers(l, 'variational_autoencoder_3rd_attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
