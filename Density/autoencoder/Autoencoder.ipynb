{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Built on Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Tensorflow and MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from sklearn import preprocessing as prep\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cross_validation as crval\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.svm import LinearSVC\n",
    "import pylab\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import csv\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: \n",
      "(5000, 14)\n",
      "Original mean: 0.189320842874 and std:2.26790054052\n",
      "After-cleaning mean: 4.3038588566e-17 and std: 1.0\n"
     ]
    }
   ],
   "source": [
    "#mnist.train.images[0:5]\n",
    "X=[]\n",
    "with open('density_data.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row1 in reader:\n",
    "        X.append(row1)\n",
    "#print size(X)\n",
    "\n",
    "X=np.asarray(X)\n",
    "X=X[:,1:15] # removing the first column since it contains indexes\n",
    "\n",
    "print 'Data dimensions: ' \n",
    "print X.shape\n",
    "\n",
    "X=X.astype(np.float)\n",
    "\n",
    "\n",
    "X= np.ravel(X)\n",
    "X= X.reshape(5000, 14)\n",
    "#print(shape(X))\n",
    "\n",
    "# splitting .. \n",
    "selX = X # (atm) we take all data --> no splitting \n",
    "\n",
    "# scaling\n",
    "std_scal=prep.StandardScaler()\n",
    "selX_scaled=std_scal.fit_transform(selX)\n",
    "print('Original mean: ' +str(mean(selX))+' and std:'+ str(std(selX)))\n",
    "print('After-cleaning mean: '+str(mean(selX_scaled))+' and std: '+str(std(selX_scaled)))\n",
    "\n",
    "\n",
    "X=selX_scaled\n",
    "#for clusters in range(3,3, 3):\n",
    "#kmeans = KMeans(n_clusters=20, random_state=0).fit(X)   \n",
    "\n",
    "#cluster_labels= kmeans.score(X)\n",
    "\n",
    "\n",
    "\n",
    "#print('done')\n",
    "#print cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load numpy and PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first image for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#img_0 = mnist.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w, h = 28, 28\n",
    "#plt.imshow(img_0.reshape((w, h)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder we are going to build is as below.\n",
    "\n",
    "![](diagram.png)\n",
    "\n",
    "With x and xp of size 28x28 and z of size 16x16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the dimension of embedded layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wz, hz = 16, 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a container for inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare variables for model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([14,wz * hz], stddev=0.1))\n",
    "b = tf.Variable(tf.truncated_normal([wz * hz], stddev=0.1))\n",
    "Wp = tf.Variable(tf.truncated_normal([wz * hz,14], stddev=0.1))\n",
    "bp = tf.Variable(tf.truncated_normal([14], stddev=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set embedded and reconstruct formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = tf.nn.relu(tf.matmul(x,W) + b)\n",
    "xp = tf.nn.sigmoid(tf.matmul(z,Wp) + bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function, optimizer and training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(x - xp))\n",
    "optimizer = tf.train.RMSPropOptimizer(0.1)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create session and initialize variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "trained = False\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ERR] Load trained model if exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gives error\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state(\"./\")\n",
    "#tf.generate_checkpoint_state_proto()\n",
    "if ckpt:\n",
    "    print \"loading: \", ckpt.model_checkpoint_path\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 14)\n"
     ]
    }
   ],
   "source": [
    "xs = X\n",
    "print xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0 loss: 1.24466\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d5667e5bfc33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'i: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./model.ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'saver' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    if trained:\n",
    "        print \"Pre-trained model loaded - training skipped.\"\n",
    "        break\n",
    "    #xs, _ = mnist.train.next_batch(64)\n",
    "    #print xs[0:10]\n",
    "    sess.run(train_step, feed_dict={x: xs})\n",
    "    if i % 1000 == 0:\n",
    "        print 'i: ', i, 'loss:', sess.run(loss, feed_dict={x: xs})\n",
    "    if i % 10000 == 0:\n",
    "        saver.save(sess, './model.ckpt', global_step=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    XP[i]=sess.run(xp, feed_dict={x: np.array([xs[i,:]])}).reshape((1, 14))\n",
    "print XP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some results (original image, embedded layer and reconstructed image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "for i in np.random.choice(range(len(mnist.train.images)), n):\n",
    "    img = mnist.train.images[i]\n",
    "    plt.figure(i)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img.reshape((w, h)), cmap='gray')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(sess.run(z, feed_dict={x: np.array([img])}).reshape((wz, hz)), cmap='gray')\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(sess.run(xp, feed_dict={x: np.array([img])}).reshape((w, h)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3D visualization\n",
    "trans_data=X_reduced_iso\n",
    "X_iso=trans_data[0,:]\n",
    "Y_iso=trans_data[1,:]\n",
    "Z_iso=trans_data[2,:]\n",
    "\n",
    "for angle in range(0, 180, 30):\n",
    "    fig = pylab.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    x=linspace(0,10,5000)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(X_iso, Y_iso, Z_iso, zorder=0.3)\n",
    "    #ax.scatter(X_iso, Z_iso, zorder=0.3)\n",
    "    \n",
    "    ax.view_init(azim=angle)\n",
    "    ax = plt.draw()\n",
    "    plt.pause(.001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
