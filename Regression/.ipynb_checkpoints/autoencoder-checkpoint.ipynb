{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto encoder for feature compression using TFlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import # Ensure no issues with \n",
    "import tflearn\n",
    "import tensorflow as tf \n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    '''Returns numpy array and panda version of the file'''\n",
    "    csv_file = csv_file +\".csv\"\n",
    "    df = pd.DataFrame()\n",
    "    df = df.from_csv(csv_file, header=0, sep=',', index_col=0)\n",
    "#n=df.shape[0] # number of samples\n",
    "#d=df.shape[1] # number of features\n",
    "    array = np.asarray(df,dtype=\"float64\")\n",
    "    if np.shape(array)[1] == 1:\n",
    "        array = array.ravel()\n",
    "    return array, df\n",
    "\n",
    "def publish_pred(y_pred, file_name):\n",
    "    df = pd.DataFrame()\n",
    "    df = df.from_csv(\"reg_sample_submission.csv\", header=0, sep=',', index_col=0)\n",
    "    df[\"Output\"] = y_pred\n",
    "    df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_in, df_in = read_csv(\"reg_train_in\")\n",
    "tr_in = np.asarray(tr_in,dtype=\"float64\")\n",
    "tr_out, df_out = read_csv(\"reg_train_out\")\n",
    "tr_out = np.asarray(tr_out,dtype=\"float64\")\n",
    "te_in, df = read_csv(\"reg_test_in\") # Still have to deal with NaNs best\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = df.from_csv(\"reg_test_gp2.csv\", header=None, sep=',', index_col=None)\n",
    "\n",
    "te_gp= np.asarray(df,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NaN = np.isnan(te_in)\n",
    "NaN_rows = []\n",
    "for i in range(1800):\n",
    "    for j in range(14):\n",
    "        if NaN[i,j]:\n",
    "            NaN_rows.append(i)\n",
    "index = list(set(range(1800))- set(NaN_rows))\n",
    "\n",
    "X_full = np.concatenate((tr_in,te_in[index,:]),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 28480 TEST: 7120\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=1,  test_size=0.20, random_state=random.randint(0,20), train_size=None) # 10_splits\n",
    "for train_index, test_index in cv.split(X_full):\n",
    "    print(\"TRAIN:\", len(list(train_index)), \"TEST:\", len(test_index))\n",
    "X_tr = X_full[list(train_index)]\n",
    "X_vl = X_full[list(test_index)]\n",
    "# VALIDATION AND TRAINING SET:\n",
    "X_tr_scale = preprocessing.StandardScaler().fit(X_tr)\n",
    "X_train = X_tr_scale.transform(X_tr)\n",
    "X_val = X_tr_scale.transform(X_vl)\n",
    "\n",
    "# DATA NOW PREPARED TO ENTER NETWORK\n",
    "X_test = X_tr_scale.transform(te_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default settings of fully connected\n",
    "tflearn.layers.core.fully_connected (incoming, n_units, activation='linear', bias=True, weights_init='truncated_normal', bias_init='zeros', regularizer=None, weight_decay=0.001, trainable=True, restore=True, reuse=False, scope=None, name='FullyConnected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = tflearn.input_data(shape=[None, 14])\n",
    "encoder = tflearn.fully_connected(encoder, 8)\n",
    "encoder = tflearn.fully_connected(encoder, 5)\n",
    "\n",
    "decoder = tflearn.fully_connected(encoder, 8)\n",
    "decoder = tflearn.fully_connected(decoder, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.regression(decoder, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='mean_square', metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14249  | total loss: \u001b[1m\u001b[32m0.01970\u001b[0m\u001b[0m | time: 1.010s\n",
      "| Adam | epoch: 050 | loss: 0.01970 -- iter: 28400/28480\n",
      "Training Step: 14250  | total loss: \u001b[1m\u001b[32m0.01967\u001b[0m\u001b[0m | time: 2.035s\n",
      "| Adam | epoch: 050 | loss: 0.01967 | val_loss: 0.02027 -- iter: 28480/28480\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(X_train, X_train, n_epoch=50, validation_set=(X_val, X_val),\n",
    "          run_id=\"auto_encoder\", \n",
    "          batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoding_model = tflearn.DNN(encoder, session=model.session)\n",
    "decoding_model = tflearn.DNN(decoder, session=model.session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_auto = np.array(decoding_model.predict(X_test.reshape(1800,14)))\n",
    "te_gp_auto = X_tr_scale.inverse_transform(X_test_auto)\n",
    "np.savetxt('te_gp_auto.csv', te_gp_auto, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python]",
   "language": "python",
   "name": "conda-env-Python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
